{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JOBLIB_MULTIPROCESSING_START_METHOD\"] = \"spawn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0095e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ops.ecris.analysis.io import read_csd_from_file_pair\n",
    "\n",
    "CSD_FILEPATHS = list(Path('./data/csds').glob('csd_*'))\n",
    "FILES_START: int = 180\n",
    "N_FILES: int = 100\n",
    "csds = [read_csd_from_file_pair(file) for file in CSD_FILEPATHS[FILES_START:FILES_START + N_FILES]]\n",
    "print(f'Loaded {len(csds)} of {len(CSD_FILEPATHS)} CSD files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bef00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.ecris.analysis.csd.m_over_q import estimate_m_over_q\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ops.ecris.analysis.model.csd import CSD\n",
    "from ops.ecris.analysis.model.element import Element\n",
    "from ops.ecris.analysis.csd.peaks import find_element_peaks\n",
    "\n",
    "def sorted_permutations(to_permute):\n",
    "    return [list(p) for p in permutations(to_permute, r=7) if list(p) == sorted(p)] \n",
    "\n",
    "def get_training_peaks(csd: CSD):\n",
    "    clear_output(wait=True)\n",
    "    csd.m_over_q = estimate_m_over_q(csd)\n",
    "    oxygen = Element('Oxygen', 'O', 16, 8)\n",
    "    o2_peaks = find_element_peaks(csd, oxygen, 0.2)\n",
    "    all_peaks, properties = find_peaks(csd.beam_current, prominence=0.1)\n",
    "    sorted_peaks = np.flip(np.argsort(properties['prominences']))\n",
    "    plt.plot(csd.m_over_q, csd.beam_current, '--')\n",
    "    plt.plot(csd.m_over_q[o2_peaks.indexes], o2_peaks.beam_current, '+')\n",
    "    for i in range(1, 9):\n",
    "        plt.axvline(16/i, ls='--', alpha=0.25, c='k')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    accept = input(\"Accept peaks? (Y/n)\")\n",
    "    if accept == 'n':\n",
    "        return []\n",
    "\n",
    "\n",
    "    for highest in [10, 15]:\n",
    "        highest_peaks = sorted(all_peaks[sorted_peaks][:highest])\n",
    "        permutations = sorted_permutations([int(v) for v in highest_peaks])\n",
    "        total_sets = len(permutations)\n",
    "        for i, p in enumerate(permutations):\n",
    "            if p == o2_peaks.indexes:\n",
    "                correct_peaks = permutations.pop(i)\n",
    "                break\n",
    "        if len(permutations) != total_sets - 1:\n",
    "            print(f'Failed to fit with {highest=} with {len(permutations)=}')\n",
    "            continue\n",
    "        if len(permutations) > 1:\n",
    "            bad_peaks = [permutations[i] for i in [random.randint(0, len(permutations) - 1) for _ in range(49)]]\n",
    "        elif len(permutations) == 1:\n",
    "            bad_peaks = permutations[0]\n",
    "        else:\n",
    "            bad_peaks = []\n",
    "        training_peaks = [correct_peaks] + bad_peaks\n",
    "        return training_peaks\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6aa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "failed = 0\n",
    "for csd in csds:\n",
    "    training_peaks = get_training_peaks(csd)\n",
    "    if not training_peaks:\n",
    "        failed += 1\n",
    "        continue\n",
    "    x.extend(training_peaks)\n",
    "    y.extend([1] + (len(training_peaks) - 1)*[0])\n",
    "print(f'{failed=}/{len(csds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array(x)\n",
    "y_array = np.array(y)\n",
    "print(x_array.shape, y_array.shape)\n",
    "x_training = np.load('x_training.npy')\n",
    "y_training = np.load('y_training.npy')\n",
    "print(x_training.shape, y_training.shape)\n",
    "x_output = np.concatenate([x_training, x_array])\n",
    "y_output = np.concatenate([y_training, y_array])\n",
    "print(x_output.shape, y_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf072e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_training.bak', x_training)\n",
    "np.save('y_training.bak', y_training)\n",
    "np.save('x_training', x_output)\n",
    "np.save('y_training', y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde24bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import StratifiedKFold, HalvingGridSearchCV\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "X_raw = np.load('x_training.npy')\n",
    "Y_raw = np.load('y_training.npy')\n",
    "\n",
    "def balance_dataset(X, y, random_state=42):\n",
    "    # Separate classes\n",
    "    X1, y1 = X[y == 1], y[y == 1]          # minority (oxygen)\n",
    "    X0, y0 = X[y == 0], y[y == 0]          # majority (non‑oxygen)\n",
    "\n",
    "    # Down‑sample majority to the size of minority (or a chosen ratio)\n",
    "    X0_down, y0_down = resample(\n",
    "        X0, y0,\n",
    "        replace=False,\n",
    "        n_samples=int(len(X1) * 3),   # 1:3 ratio (tune as needed)\n",
    "        random_state=random_state)\n",
    "\n",
    "    X_bal = np.vstack([X1, X0_down])\n",
    "    y_bal = np.hstack([y1, y0_down])\n",
    "    return X_bal, y_bal\n",
    "\n",
    "X, Y = balance_dataset(X_raw, Y_raw)\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(random_state=42, \n",
    "                                                                         max_iter=500, \n",
    "                                                                         early_stopping=True, \n",
    "                                                                         n_iter_no_change=10, \n",
    "                                                                         verbose=False))\n",
    "                                                                         ])\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [\n",
    "        (5,), (7,), (10,), (14,), (20,), (30,), (50,), (100,),\n",
    "        (10, 5), (14, 7), (20, 10), (30, 15), (50, 25), (100, 50),\n",
    "        (20, 10, 5), (30, 15, 7), (50, 25, 10), (100, 50, 20)\n",
    "    ],\n",
    "    'mlp__activation': ['relu', 'tanh'],\n",
    "    'mlp__solver': ['adam', 'sgd'],\n",
    "    'mlp__alpha': [1e-5, 1e-4, 1e-3],\n",
    "    'mlp__learning_rate_init': [1e-4, 1e-3, 1e-2],\n",
    "    'mlp__batch_size': [32, 64, 128],\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "    'mlp__validation_fraction': [0.1, 0.2],\n",
    "    'mlp__n_iter_no_change': [10, 20],\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = HalvingGridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,               \n",
    "    verbose=2,               \n",
    "    refit=True,              #\n",
    "    return_train_score=True\n",
    ")\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac1366",
   "metadata": {},
   "source": [
    "## Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "best_pipe = grid.best_estimator_\n",
    "params = grid.best_params_\n",
    "model_path = Path('mlp_csd_oxygen.pkl')\n",
    "params_path = Path('mlp_csd_oxygen_params.json')\n",
    "joblib.dump(best_pipe, model_path)\n",
    "with open(params_path, 'w') as f:\n",
    "    json.dump(params, f, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5a936",
   "metadata": {},
   "source": [
    "## Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "clf = joblib.load('mlp_csd_oxygen.pkl')\n",
    "\n",
    "def estimate_correct_peaks(csd):\n",
    "    all_peaks, properties = find_peaks(csd.beam_current, prominence=0.1, height=(10, None))\n",
    "    sorted_peaks = np.flip(np.argsort(properties['prominences']))\n",
    "    highest_peaks = sorted(all_peaks[sorted_peaks][:10])\n",
    "    sorted_peaks = sorted_permutations([int(v) for v in highest_peaks])\n",
    "    return sorted_peaks, clf.predict_proba(sorted_peaks)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSD_FILEPATHS = list(Path('./data/csds').glob('csd_*'))\n",
    "FILE_NUM = random.randint(0, len(CSD_FILEPATHS))\n",
    "csd = read_csd_from_file_pair(CSD_FILEPATHS[FILE_NUM])\n",
    "estimated_peaks, probabilities = estimate_correct_peaks(csd)\n",
    "highest_prob = np.flip(np.argsort(probabilities))[0]\n",
    "csd.m_over_q = estimate_m_over_q(csd)\n",
    "\n",
    "plt.plot(csd.m_over_q, csd.beam_current, '--')\n",
    "\n",
    "highest_peaks = estimated_peaks[highest_prob]\n",
    "plt.plot(csd.m_over_q[highest_peaks], csd.beam_current[highest_peaks], '+')\n",
    "for i in range(1, 9):\n",
    "    plt.axvline(16/i, ls='--', alpha=0.25, c='k')\n",
    "plt.xlabel('M/Q (Estimated)')\n",
    "plt.ylabel(r'Beam current ($\\mu$A)')\n",
    "plt.xlim([0,10])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f'Estimated probability of O2 detection: {probabilities[highest_prob]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041903f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.flip(np.argsort(probabilities[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece55d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
